# -*- coding: utf-8 -*-
"""IMDB-Bert.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j6_oIzNp3WnlBmlOpk6jITpeKunZwx80
"""

!pip install ktrain
!git clone https://github.com/laxmimerit/IMDB-Movie-Reviews-Large-Dataset-50k.git
!pip install git+https://github.com/laxmimerit/preprocess_kgptalkie.git

import pandas as pd
import numpy as np
import ktrain
from ktrain import text
import tensorflow as tf

import matplotlib.pyplot as plt
import seaborn as sns

from wordcloud import WordCloud

from collections import Counter
import preprocess_kgptalkie as kgp

"""## **Download data**"""

data_train = pd.read_excel('/content/IMDB-Movie-Reviews-Large-Dataset-50k/train.xlsx', dtype = str)
data_test = pd.read_excel('/content/IMDB-Movie-Reviews-Large-Dataset-50k/test.xlsx', dtype= str)

"""## **Data preprocessing and visualization**"""

data_train.head()

data_train.shape

data_train.info()

semtiment_count = Counter(data_train.Sentiment)
plt.bar(semtiment_count.keys(), semtiment_count.values())
plt.title("Dataset labels distribuition")

data_train['Sentiment'].value_counts()

data_train=data_train.rename(columns={'Reviews': 'text'})

kgp.get_basic_features(data_train)

sns.distplot(data_train['char_counts'])

sns.kdeplot(data_train[data_train['Sentiment']=='neg']['char_counts'], shade=True, color='red')
sns.kdeplot(data_train[data_train['Sentiment']=='pos']['char_counts'], shade=True, color='blue')

sns.kdeplot(data_train[data_train['Sentiment']=='neg']['word_counts'], shade=True, color='red')
sns.kdeplot(data_train[data_train['Sentiment']=='pos']['word_counts'], shade=True, color='blue')

sns.kdeplot(data_train[data_train['Sentiment']=='neg']['avg_wordlength'], shade=True, color='red')
sns.kdeplot(data_train[data_train['Sentiment']=='pos']['avg_wordlength'], shade=True, color='blue')

sns.kdeplot(data_train[data_train['Sentiment']=='neg']['stopwords_counts'], shade=True, color='red')
sns.kdeplot(data_train[data_train['Sentiment']=='pos']['stopwords_counts'], shade=True, color='blue')

def get_clean(x):
    x = str(x).lower().replace('\\', ' ').replace('_', ' ').replace('.', ' ')
    x = kgp.cont_exp(x)
    x = kgp.remove_emails(x)
    x = kgp.remove_urls(x)
    x = kgp.remove_html_tags(x)
    x = kgp.remove_rt(x)
    x = kgp.remove_accented_chars(x)
    x = kgp.remove_special_chars(x)
    x = kgp.remove_dups_char(x)
    return x

data_train['text'] = data_train['text'].apply(lambda x: get_clean(x))

data_train=data_train.rename(columns={'text': 'Reviews'})

positive = kgp.get_word_freqs(data_train[data_train['Sentiment']=='pos'], 'Reviews')
positive = ' '.join(positive.index)

word_cloud = WordCloud(max_font_size=100).generate(positive)
plt.imshow(word_cloud)
plt.axis('off')
plt.show()

negative = kgp.get_word_freqs(data_train[data_train['Sentiment']=='neg'], 'Reviews')
negative = ' '.join(negative.index)
word_cloud = WordCloud(max_font_size=100).generate(negative)
plt.imshow(word_cloud)
plt.axis('off')
plt.show()

data_train.head()

data_train.drop(['char_counts','word_counts','avg_wordlength','stopwords_counts','hashtag_counts','mentions_counts','digits_counts','uppercase_counts'],axis=1	)

"""# **DistilBERT Training**"""

(train, val, preproc) = text.texts_from_df(train_df=data_train, text_column='Reviews', label_columns='Sentiment',
                   val_df = data_test,
                   maxlen = 400,
                   preprocess_mode = 'distilbert')

model = text.text_classifier(name = 'distilbert', train_data = train, preproc=preproc)

learner = ktrain.get_learner(model = model,
                             train_data = train,
                             val_data = val,
                             batch_size = 6)

learner.fit_onecycle(lr = 2e-5, epochs=2)

learner.fit_onecycle(lr = 2e-5, epochs=1)

predictor = ktrain.get_predictor(learner.model, preproc)
predictor.save('distilbert')

